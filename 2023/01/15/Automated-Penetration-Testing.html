<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Reinforcement Learning in Automatic Penetration Testing | Yizhou Yang Personal Page</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Reinforcement Learning in Automatic Penetration Testing" />
<meta name="author" content="Yizhou Yang" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="Red Teaming: Beyond Penetration Testing for Ultimate Security Assessment" />
<meta property="og:description" content="Red Teaming: Beyond Penetration Testing for Ultimate Security Assessment" />
<meta property="og:site_name" content="Yizhou Yang Personal Page" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-15T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Reinforcement Learning in Automatic Penetration Testing" />
<meta name="twitter:site" content="@Lord_Rayleigh55" />
<meta name="twitter:creator" content="@Yizhou Yang" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yizhou Yang"},"dateModified":"2023-01-15T00:00:00+08:00","datePublished":"2023-01-15T00:00:00+08:00","description":"Red Teaming: Beyond Penetration Testing for Ultimate Security Assessment","headline":"Reinforcement Learning in Automatic Penetration Testing","mainEntityOfPage":{"@type":"WebPage","@id":"/2023/01/15/Automated-Penetration-Testing.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/assets/img/smile.png"},"name":"Yizhou Yang"},"url":"/2023/01/15/Automated-Penetration-Testing.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav>
      <ul>
        
        <!-- others -->
        <a href="/">
          <li class="btn-nav">Home</li>
        </a>
        
          <a href="/publications">
            <li class="btn-nav">Publications</li>
          </a>
        
        
        
          <a href="/blog">
            <li class="current btn-nav">Blog</li>
          </a>
          <a href="/tags">
            <li class="btn-nav">Tags</li>
          </a>
        
        
      </ul>
    </nav>
  </header>
</section>
<div id="post">
  <section class="post-header">
    <h1 class="title">Reinforcement Learning in Automatic Penetration Testing</h1>
    <p class="subtitle">Unleashing the Power of Red Team Operations</p>
    <p class="meta">
      January 15, 2023
    </p>
  </section>
  <section class="post-content">
    <h2 id="red-teaming-beyond-penetration-testing-for-ultimate-security-assessment">Red Teaming: Beyond Penetration Testing for Ultimate Security Assessment</h2>

<p>In today’s rapidly evolving security landscape, addressing the formidable Advanced Persistent Threats (APTs) has become an increasingly complex task. Enter the concept of a “Red Team” - a game-changing approach to security assessment that goes beyond traditional penetration testing.</p>

<blockquote>
  <p>The terms “red team” and “penetration test” are often used interchangeably, even though they have distinct purposes and approaches.</p>
  <h3 id="introduction-to-red-team-operations-emulating-real-world">Introduction to Red Team Operations: Emulating Real-World</h3>
  <p><img src="./figures/auto-red-team/flow_chart.png" alt="[https://vulnsign.com/red-teaming](https://vulnsign.com/red-teaming)" /></p>
</blockquote>

<p><a href="https://vulnsign.com/red-teaming">https://vulnsign.com/red-teaming</a></p>

<p>Unlike conventional penetration tests, which aim to uncover as many vulnerabilities as possible, a Red Team Assessment takes a more targeted approach. Its objective is not just to find weaknesses but to put an organization’s detection and response capabilities to the ultimate test. Emulating the tactics of a real-world attacker, the Red Team endeavors to gain access to sensitive information by any means necessary.</p>

<h3 id="sequential-decision-making-replicating-adversaries-tactics">Sequential Decision-Making: Replicating Adversaries’ Tactics</h3>

<p>To accurately replicate the tactics employed by adversaries, Red Team operations follow a sequential decision-making process, much like a well-planned campaign. Adversaries systematically progress through different stages, building upon each success to achieve their objectives. To ensure a comprehensive replication of these techniques, Red Team practices should adopt a sequential approach aligned with the attacker’s methodology, leveraging the <strong>MITRE Att&amp;CK</strong> framework. When applied to penetration testing, this structured and systematic approach enables testers to navigate their engagements with precision.</p>

<p>While the efficacy of Red Teaming or Penetration testing is undeniable, the human effort and cost involved can present significant challenges. Thankfully, the solution lies in the integration of intelligent automation. By harnessing the power of automated tools and technologies, organizations can streamline and augment their security assessments, empowering their teams to focus on strategic decision-making and stay one step ahead of potential threats.</p>

<p><a href="https://github.com/infosecn1nja/AD-Attack-Defense">https://github.com/infosecn1nja/AD-Attack-Defense</a></p>

<h2 id="the-limitations-of-planning-embracing-dynamic-policies-in-a-complex-world">The Limitations of Planning: Embracing Dynamic Policies in a Complex World</h2>

<p>Planning is generally considered a good and straightforward approach. It helps us set goals, make schedules, and organize our actions to achieve desired outcomes. However, life is full of surprises, and sometimes unexpected events occur that can throw a wrench in our carefully laid plans. For instance, imagine you have diligently scheduled a date, but due to unforeseen circumstances like having to work overtime, you end up missing it.</p>

<p>In such situations, it becomes necessary to have backup plans in place. These backup plans, often referred to as plan B, plan C, and so on, act as alternative strategies that can be implemented when our initial plans go awry. They serve as contingency measures to help us navigate through unexpected disruptions.</p>

<p>The effectiveness of these backup plans depends on our ability to anticipate and understand what might happen in different scenarios—a concept known as having a “world model” or a comprehensive awareness of our surroundings. This world model allows us to predict possible obstacles or challenges that might arise and develop backup plans accordingly. However, relying solely on a rigid and static world model has its limitations.</p>

<p>The process of identifying potential incidents and generating backup plans is a complex task that requires substantial human effort. It becomes even more challenging when faced with situations that go beyond the known incidents we have prepared for. Unexpected events that we couldn’t have anticipated can occur simultaneously or deviate from our expectations, making it difficult to respond effectively.</p>

<p>This is where the concept of a dynamic policy comes into play. A dynamic policy is flexible and adaptable, capable of adjusting to changing circumstances. It doesn’t rely solely on predefined plans but rather learns from experience and interacts with its environment to make informed decisions. One effective approach to developing such dynamic policies is through reinforcement learning.</p>
<h2 id="reinforcement-learning-unlocking-the-potential-of-dynamic-policies">Reinforcement Learning: Unlocking the Potential of Dynamic Policies</h2>
<p>Reinforcement learning is a machine learning technique that allows an agent to learn and improve its decision-making process through trial and error. It learns by receiving feedback or rewards based on its actions and adjusts its behavior accordingly. This approach enables the agent to learn a policy—a set of rules or guidelines—that can adapt to unexpected situations and perform at a level comparable to human performance.</p>

<p><img src="./figures/auto-red-team/rl.png" alt="" /></p>

<p>Projects like AlphaStar and OpenAI Five have demonstrated the power of reinforcement learning in creating dynamic and adaptable policies. For example, AlphaStar, developed by DeepMind, achieved remarkable success in playing the game StarCraft II at a professional level. OpenAI Five, on the other hand, showcased impressive teamwork and coordination in the game Dota 2. These projects highlight how reinforcement learning can enable AI systems to navigate complex and dynamic environments, making decisions that rival human capabilities.</p>

<p>By leveraging reinforcement learning to develop dynamic policies, we can enhance our ability to respond effectively to unexpected events. These policies can adapt and adjust to changing circumstances, offering us a more robust and reliable approach to handling disruptions and achieving desired outcomes.</p>

<h2 id="revolutionizing-red-team-operations-with-reinforcement-learning">Revolutionizing Red Team Operations with Reinforcement Learning</h2>

<p>The objective of incorporating reinforcement learning into automated red team operations is to enhance the efficacy of deep learning-based control techniques within realistic red team scenarios. In this context, an automated red team agent, represented by a neural network, utilizes the current network observation as input and generates optimal attack decisions as output.</p>

  </section>
</div>

<div id="top" class="top-btn" onclick="moveTop()">
  <i class="fas fa-chevron-up"></i>
</div>

<script>
  var lastScrollTop = 0;
  window.onscroll = function () {
    var st = document.body.scrollTop || document.documentElement.scrollTop;
    if (st > 250) {
      document.getElementById("top").style.display = "block"
      if (st > lastScrollTop) {
        document.getElementById("top").style.opacity = 0
      } else {
        document.getElementById("top").style.opacity = 1
      }
    } else {
      document.getElementById("top").style.opacity = 0
      if (st > lastScrollTop) {
        document.getElementById("top").style.display = "none"
      }
    }
    lastScrollTop = st <= 0 ? 0 : st;
  }
  function moveTop() {
    document.body.scrollTop = 0
    document.documentElement.scrollTop = 0
  }
</script>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2022
    <a href=""></a>.
    Powered by Jekyll with
    <a href="https://github.com/chrjabs/Grape-Academic-Theme">Grape Academic Theme</a>.
  </div>
</footer>

  </div>
</body>

</html>